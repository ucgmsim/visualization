# Disagg and Scenario Plot generation

Creating hazard maps is split into the following steps:
1. Generate hazard map data for ensembles of interest
2. Optionally: Compute ratios between ensembles, if ratio plot are required
3. Plot actual hazard maps

Note: Plotting is currently incomplete and only supports ratio plot mapping, however
it should be trivial to add support for non-ratio hazard map plots

## Standard hazard maps - Data generation
Data for standard hazard maps is generated by generating a shell script using the 
gen_hazard_map_script.py, which can then be used to run the actual 
hazard map data collection.

The **gen_hazard_map_script.py** takes the following options
```shell script
usage: gen_hazard_map_script.py [-h] [--maui]
                                run_hazard_map_calc_ffp out_script_ffp
                                output_dir config_ffp

positional arguments:
  run_hazard_map_calc_ffp
                        File path to the run_hazard_map_calc.py script
  out_script_ffp        The file path of the output bash script
  output_dir            The output directory for the hazard map data
  config_ffp            The yaml config file that specifies which combinations
                        to run

optional arguments:
  -h, --help            show this help message and exit
  --maui
  --nz_code             If set then the hazard is generated using the NZ code 
```
Where the config file has the format:
```yaml
combinations:
  v18p6sim:
    ims:
      - "PGA"
      - "pSA_0.1"
      - "pSA_0.2"
    excd_prob:
      - {percentage: 50, years: 50}
      - {percentage: 10, years: 50}
    n_procs: 3
  v18p6emp:
    ims:
      - "PGA"
      - "pSA_0.1"
      - "pSA_0.2"
    excd_prob:
      - {percentage: 50, years: 50}
      - {percentage: 10, years: 50}
    n_procs: 3
```
The n_procs option specifies how many processes each combination uses, 
i.e. the total number of combination for an ensemble is given by:
```
n_procs * (number of ims entries) * (number of excd_prob entries)
```
For the example config the total number of processes is then:
```
(3 * 3 * 2) + (3 * 3 * 2)  = 36
```

#### Example:
```shell script
python ./gen_hazard_map_script.py ../../run_hazard_map_calc.py /home/cbs51/code/tmp/maps/run_hazard.sh /home/cbs51/code/tmp/maps ./ ./gen_hazard_map_script_config.yaml
```

which will generate a shell script that looks something like this:
```shell script
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim PGA 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_PGA_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_PGA_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_0.1 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_0p1_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_0p1_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_0.2 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_0p2_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_0p2_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_0.5 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_0p5_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_0p5_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_1.0 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_1p0_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_1p0_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_2.0 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_2p0_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_2p0_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_3.0 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_3p0_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_3p0_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6sim pSA_5.0 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_5p0_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6sim_pSA_5p0_50_50.log &
python3 /home/cbs51/code/seistech/seistech_scripts/seistech_scripts/local/run_hazard_map_calc.py v18p6emp PGA 0.013862943611198907 /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6emp_PGA_50_50.csv --n_procs 1 --exceedance_title '50% in 50 years' > /data/cbs51/191114_cs18p6_sim_vs_emp_RP_maps/v18p6emp_PGA_50_50.log &
```

which can then be executed to actually run the hazard map data calculation, producing 
output files following the naming convention: 
```shell script
ensembleID_IM_probability_years.csv
```
The output file will have the columns: *station_name*, *lon*, *lat*, *value*

A .json file with the same filename is also generated, which contains metadata, such
as the ensemble_id, IM.

## Generating ratio data from standard hazard map data
This is done using the **compute_ratios.py** script, which take the following options
```shell script
usage: compute_ratio_data.py [-h] [--lat_max_filter LAT_MAX_FILTER]
                             data_dir prefix_1 prefix_2

positional arguments:
  data_dir              Data directory that contains the hazard map data
  prefix_1              Prefix of the filenames for the numerator for the
                        ratio calculation ln(prefix_1/prefix_2)
  prefix_2              Prefix of the filenames for denominator

optional arguments:
  -h, --help            show this help message and exit
  --lat_max_filter LAT_MAX_FILTER
                        All entries with lat > lat_max_filter are removed
```
The script requires the filenames to have different prefixes,
but otherwise the same name (for the same IM & return period)

E.g. if "prefix_1 = v18p6sim" and "prefix_2 = v18p6emp" and the files in the data dir are   
- v18p6emp_pSA_3p0_2_50.csv
- v18p6emp_pSA_3p0_10_50.csv
- v18p6sim_pSA_3p0_2_50.csv
- v18p6sim_pSA_3p0_10_50.csv

then two ratio files will be created as follows:
- v18p6sim_pSA_3p0_2_50.csv / v18p6emp_pSA_3p0_2_50.csv
- v18p6sim_pSA_3p0_10_50.csv / v18p6emp_pSA_3p0_10_50.csv

where the resulting files have are named using the following format
```
prefix1_vs_prefix2_commonName.csv
```
Again a .json metadata file is generated
The output file will have the columns: *station_name*, *lon*, *lat*, *value*

The lat_max_filter is useful to exclude stations in Northland, which can produce values that 
are problematic for plotting (using a value of -36.3 works well)
 

## Event based hazard maps - Data generation
Event based data generation can either be done at the ensemble (**ensemble_event_map_runner.py**) 
or the IMDB (**imdb_event_map_runner.py**), and the can either be ratio or just single data source.

Note: Currently only single-source is currently supported at IMDB level and ratio at ensemble level,
however it is straightforward to add support for ratio and single-source respectively.

Both scripts in turn use the **gen_median_diff_map_data.py** script, which can also be
directly used to generate single-source or ratio data for a single rupture.

The **ensemble_event_map_runner.py** has the following options:
```shell script
usage: median_diff_map_runner.py [-h] [--n_procs N_PROCS]
                                 [--lat_max_filter LAT_MAX_FILTER]
                                 ensemble_id_1 ensemble_id_2 station_list_ffp
                                 output_dir

positional arguments:
  ensemble_id_1         The ensemble id of the first ensemble, note the ratio
                        is computed as ln(ensemble_id/ensemble_id)
  ensemble_id_2
  station_list_ffp      Station list file
  output_dir

optional arguments:
  -h, --help            show this help message and exit
  --n_procs N_PROCS
  --lat_max_filter LAT_MAX_FILTER
                        All station with lat > lat_max_filter are ignored
```

And the **imdb_event_map_runner.py** script has the options:
```shell script
usage: imdb_event_map_runner.py [-h] [--n_procs N_PROCS]
                                [--lat_max_filter LAT_MAX_FILTER]
                                imdb_ff output_dir

positional arguments:
  imdb_ff               The file path to the imdb
  output_dir

optional arguments:
  -h, --help            show this help message and exit
  --n_procs N_PROCS
  --lat_max_filter LAT_MAX_FILTER
                        All station with lat > lat_max_filter are ignored
```

The lat_max_filter is useful to exclude stations in Northland, which can produce values that 
are problematic for plotting (using a value of -36.3 works well)

Running this script will produce output files in the format:
Ratio:
```
id1_vs_id2_IM_probability_years.csv
```
Single-source:
```
id_IM_probability_years.csv
```
where id is either the IMDB name or ensemble_id.
A metadata json file is also generated.

The output file will have the columns: *station_name*, *lon*, *lat*, *value*

## Plotting

### Ratio plots
Plotting is done using the **plot_ratios.py** script, which has the following options:
```shell script
usage: plot_ratios.py [-h] [--recursive] [--n_procs N_PROCS] [--no_clobber]
                      plot_items_ffp data_dir file_filter plot_options_config

positional arguments:
  plot_items_ffp
  data_dir             Based data directory
  file_filter          Glob filter that will be used to select the files to
                       plot
  plot_options_config  Config file with the gmt plot options

optional arguments:
  -h, --help           show this help message and exit
  --recursive          If set then glob searches for files recursively
  --n_procs N_PROCS
  --no_clobber         If set, then existing ratio plots are not overwritten
```

where the config has the following format:
```yaml
flags:
  - "xyz-grid"
  - "xyz-landmask"
  - "xyz-grid-contours"
options:
#  xyz-grid-type: "nearneighbor"
#  xyz-grid-search: "12k"

  xyz-grid-search: "12m"
  xyz-grid-automask: "12k"
  xyz-cpt: "polar"
  xyz-cpt-bg: "0/0/80"
  xyz-cpt-fg: "80/0/0"
  xyz-transparency: "30"
  xyz-size: "1k"
  xyz-cpt-inc: "0.16"
  xyz-cpt-tick: "0.3"
  xyz-cpt-min: "-1.2"
  xyz-cpt-max: "1.2"
```

#### Example
```shell script
python plot_ratios.py /home/nesi00213/visualization/visualization/gmt/plot_items.py /home/cbs51/code/data/191122_cs18p6_sim_vs_emp_event_maps "*/*median.xyz" ./plot_options.yaml --n_procs 16 --no_clobber
```

The input files are expected to be csv files with the columns: *lon*, *lat*, *value*

The resulting plots will have the same name as the files found by the filter, 
with the extension changed to .png

Note: Some of the gmt processes might get stuck, which has something to do with the surface interpolation,
the only way around this issue is to use the two options that are commented out and disabling 
```yaml
  xyz-grid-search: "12m"
  xyz-grid-automask: "12k"
```

